{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs1yrbpnQ3DG"
      },
      "source": [
        "# Segmentation Practical\n",
        "\n",
        "In this notebook, we will learn how to identify objects based on their color and extract the center and area of these objects.  \n",
        "\n",
        "Throughout this notebook, complete **Exercises** and **`TODO` sections** in code blocks.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Getting Started](#GettingStarted)\n",
        "1. [Loading Photos](#LoadingPhotos)\n",
        "1. [Color Formats](#ColorFormats)\n",
        "1. [Masks](#Masks)\n",
        "1. [Finding Contours](#FindingContours)\n",
        "1. [Contour Center](#ContourCenter)\n",
        "1. [Contour Area](#ContourArea)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_tQzkfwQ3DS"
      },
      "source": [
        "<a id=\"GettingStarted\"></a>\n",
        "## 1. Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APFuYrBcQ3DU"
      },
      "source": [
        "First, we will import the necessary libraries for this notebook, including Python libraries (`cv`, `numpy`, etc.) and helpers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xzwoCCbNQ3DV"
      },
      "outputs": [],
      "source": [
        "# Import Python libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrJgkx1RQ3DY"
      },
      "source": [
        "The following functions will help us throughout this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aZyLLqqNQ3DZ"
      },
      "outputs": [],
      "source": [
        "def draw_contour(image, contour, color=(0, 255, 0)):\n",
        "    \"\"\"\n",
        "    Draws a contour on the provided image.\n",
        "\n",
        "    Args:\n",
        "        image: The image on which to draw the contour.\n",
        "        contour: The contour to draw on the image.\n",
        "        color: The color to draw the contour in BGR format.\n",
        "    \"\"\"\n",
        "    cv2.drawContours(image, [contour], 0, color, 3)\n",
        "\n",
        "    \n",
        "def draw_circle(color_image, center, color=(0, 255, 255), radius=6):\n",
        "    \"\"\"\n",
        "    Draws a circle on the provided image.\n",
        "\n",
        "    Args:\n",
        "        color_image: The color image on which to draw the contour.\n",
        "        center: The pixel (row, column) of the center of the image.\n",
        "        color: The color to draw the circle in BGR format.\n",
        "        radius: The radius of the circle in pixels.\n",
        "    \"\"\"\n",
        "    # cv.circle expects the center in (column, row) format\n",
        "    cv2.circle(color_image, (center[1], center[0]), radius, color, -1)\n",
        "\n",
        "    \n",
        "def show_color_rgb(red, green, blue):\n",
        "    \"\"\"\n",
        "    Displays a color specified in the RGB format.\n",
        "    \"\"\"\n",
        "    rectangle = plt.Rectangle((0,0), 50, 50, fc=(red/255, green/255, blue/255))\n",
        "    plt.gca().add_patch(rectangle)\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "def show_color_hsv(hue, saturation, value):\n",
        "    \"\"\"\n",
        "    Displays a color specified in the HSV format\n",
        "    \"\"\"\n",
        "    # Convert from hsv to rgb\n",
        "    hsv = np.array([[[hue, saturation, value]]], np.uint8)\n",
        "    rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "    \n",
        "    show_color_rgb(rgb[0][0][0], rgb[0][0][1], rgb[0][0][2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x0WjL-sQ3Dh"
      },
      "source": [
        "<a id=\"LoadingPhotos\"></a>\n",
        "## 2. Loading Photos\n",
        "Here we will load some photos of stop signs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_gm0W_GQ3Di",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Load some stop sign images and add them to an array\n",
        "stopsigns = glob.glob(\"stopsigns/*.jpg\")\n",
        "stopsigns = [cv2.imread(s, cv2.IMREAD_COLOR) for s in stopsigns]\n",
        "print( \"{} stop signs in dataset\".format(len(stopsigns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question\n",
        "We have opened these images using OpenCV. What color format are these images in? BGR or RGB? If you need a hint, run the next cell...\n",
        "\n",
        "docs.opencv.org/3.4.1/d3/df2/tutorial_py_basic_ops.html"
      ],
      "metadata": {
        "id": "iN3eix_tt2CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show one of the stop signs\n",
        "plt.imshow(stopsigns[0]);"
      ],
      "metadata": {
        "id": "ErI_iWSytG4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1\n",
        "\n",
        "Convert one of the 20 stop sign images from BGR to RGB (cv2.cvtColor(YOUR_IMAGE, cv2.COLOR_BGR2RGB)) and to HSV. \n",
        "\n",
        "For each colorspace, visualize the three channels by displaying the image.\n",
        "\n",
        "Which colorspace isolates the stop sign the best?"
      ],
      "metadata": {
        "id": "9AEUNp9PuQZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, select the desired stop sign from the set fo 21 images loaded above\n",
        "desired_sign = # TODO: Enter a stop sign number from 0-20 here\n",
        "sign_img = stopsigns[desired_sign]\n",
        "\n",
        "# And display it in it's native format\n",
        "plt.imshow(sign_img);"
      ],
      "metadata": {
        "id": "nCataf1n0ohB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now convert and display it in RGB format\n",
        "rgb_img = # TODO: Your code here to convert sign_img to RGB\n",
        "plt.imshow(rgb_img);"
      ],
      "metadata": {
        "id": "qVVUQFh0uUIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And convert and display it in HSV format\n",
        "hsv_img =  # TODO: Your code here to convert to HSV\n",
        "plt.imshow(hsv_img);"
      ],
      "metadata": {
        "id": "HuRDDj92vXyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wcvl5r0KQ3Dk"
      },
      "source": [
        "Color images are stored as three dimensional numpy arrays:\n",
        "\n",
        "* **0th dimension**: pixel rows, indexed from top to bottom.\n",
        "* **1st dimension**: pixel columns, indexed from left to right.\n",
        "* **2nd dimension**: pixel color values, ordered red, green, blue, each ranging from 0 (none of that color) to 255 (maximum amount of that color).\n",
        "\n",
        "Let's look at the color values of the middle pixel of our image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWHJiM-2Q3Dl",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Display the image dimensions\n",
        "img_shape = rgb_img.shape\n",
        "print(img_shape)\n",
        "print(\"rows: {}\".format(img_shape[0]))\n",
        "print(\"columns: {}\".format(img_shape[1]))\n",
        "\n",
        "# Calculate center row and column\n",
        "row = rgb_img.shape[0] // 2\n",
        "col = rgb_img.shape[1] // 2\n",
        "\n",
        "# Extract and print blue, green, and red values\n",
        "red = rgb_img[row][col][0]\n",
        "green = rgb_img[row][col][1]\n",
        "blue = rgb_img[row][col][2]\n",
        "\n",
        "print(\"red:\", red)\n",
        "print(\"green:\", green)\n",
        "print(\"blue:\", blue)\n",
        "\n",
        "# Display this color\n",
        "show_color_rgb(red, green, blue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlLYvvF0Q3Dm"
      },
      "source": [
        "## Exercise 2\n",
        "Update `row` and `col` in the following code block to show a pixel that you expect to be strongly blue, green, or red based on the stop sign image you have loaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11ZjNao3Q3Dn"
      },
      "outputs": [],
      "source": [
        "# TODO: Identify the desired row and column \n",
        "row = 0\n",
        "col = 0\n",
        "\n",
        "# Extract and print red, green, and blue values\n",
        "red = rgb_img[row][col][0]\n",
        "green = rgb_img[row][col][1]\n",
        "blue = rgb_img[row][col][2]\n",
        "\n",
        "print(\"red:\", red)\n",
        "print(\"green:\", green)\n",
        "print(\"blue:\", blue)\n",
        "\n",
        "# Display this color\n",
        "show_color_rgb(red, green, blue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uQLY1MCQ3Do"
      },
      "source": [
        "<a id=\"ColorFormats\"></a>\n",
        "## 3. Color Formats\n",
        "By default, the images loaded with OpenCV are stored in the blue-green-red (BGR) format, and image plotting in matplotlib assumes the red-green-blue (RGB) format.  However, when recognizing objects based on their color, it is far easier to use yet another format, the hue-saturation-value (HSV) format, in which each channel corresponds to the following:\n",
        "\n",
        "* **Hue** (0 to 180): The color as it appears on a color wheel, ordered as red-orange-yellow-green-blue-purple-red\n",
        "* **Saturation** (0 to 255): The amount of white added to the color.  0 is pure white, and 255 is the pure color without any white added.\n",
        "* **Value** (0 to 255): The amount of black added to the color.  0 is pure black, and 255 is the pure color without any black added.\n",
        "\n",
        "While saturation and value vary with lighting, hue will remain mostly the same regardless of lighting.  By focusing on the hue of the object we are attempting to detect, we can find it even in different lighting environments."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3\n",
        "\n",
        "We can use the following widgets to experiment with different color values in the RGB and HSV formats.  \n",
        "\n",
        "**For both formats, find the values which produce the following colors: orange, red, dark green, and blue.**"
      ],
      "metadata": {
        "id": "A7Wdhitg21H6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOlm7HxtQ3Do",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# RGB color\n",
        "widgets.interact(show_color_rgb,\n",
        "                 red=widgets.IntSlider(0, 0, 255, continuous_update=False),\n",
        "                 green=widgets.IntSlider(0, 0, 255, continuous_update=False),\n",
        "                 blue=widgets.IntSlider(0, 0, 255, continuous_update=False));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbt4_TkWQ3Dq",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# HSV color\n",
        "widgets.interact(show_color_hsv,\n",
        "                 hue=widgets.IntSlider(0, 0, 180, continuous_update=False),\n",
        "                 saturation=widgets.IntSlider(255, 0, 255, continuous_update=False),\n",
        "                 value=widgets.IntSlider(255, 0, 255, continuous_update=False));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NyazUj1Q3Dr"
      },
      "source": [
        "<a id=\"Masks\"></a>\n",
        "## 4. Masks\n",
        "Lets work on identifying an object in the image based on its color.  Specifically, we will isolate the portions of an image which fall within a certain color range by defining **upper** and **lower** HSV bounds.  We will use that to create a *mask* - a special type of image which is white in areas to include and black in areas not to include.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4\n",
        "\n",
        "**Finish writing the function `get_mask` below, which takes an image and returns a mask of the areas between hsv_lower and hsv_upper.**  You will likely wish to use the following OpenCV functions:\n",
        "\n",
        "* `cvtColor`(docs.opencv.org/4.2.0/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab)\n",
        "   * Converts an image from one color format to another, such as from RGB to HSV.\n",
        "* `inRange`(docs.opencv.org/4.2.0/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981)\n",
        "   * Creates a mask from an image based on a lower and upper color bound."
      ],
      "metadata": {
        "id": "5HMiKweq3Y1t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuZLy6aVQ3Dr"
      },
      "outputs": [],
      "source": [
        "def get_mask(image, hsv_lower, hsv_upper):\n",
        "    \"\"\"   \n",
        "    Returns a mask containing all of the areas of image which were between hsv_lower and hsv_upper.\n",
        "    \n",
        "    Args:\n",
        "        image: The image (stored in BGR) from which to create a mask.\n",
        "        hsv_lower: The lower bound of HSV values to include in the mask.\n",
        "        hsv_upper: The upper bound of HSV values to include in the mask.\n",
        "    \"\"\"\n",
        "    # Convert hsv_lower and hsv_upper to numpy arrays so they can be used by OpenCV\n",
        "    hsv_lower = np.array(hsv_lower)\n",
        "    hsv_upper = np.array(hsv_upper)\n",
        "    \n",
        "    # TODO: Use the cv.cvtColor function to switch our RGB colors to HSV colors\n",
        "    \n",
        "    # TODO: Use the cv.inRange function to highlight areas in the correct range\n",
        "\n",
        "    \n",
        "    return mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vDLJLYjQ3Du"
      },
      "source": [
        "## Exercise 5\n",
        "Next, we will use the `get_mask` function to create a mask containing just the stop sign in our `sign_img`.  At the moment, `hsv_lower` and `hsv_upper` include all possible HSV values, so the mask will contain the entire image.  \n",
        "\n",
        "**Tune the values of `hsv_lower` and `hsv_upper` until the mask only includes the cone(s).**\n",
        "\n",
        "**Hints:**\n",
        "\n",
        "* Use the HSV color widget from the **Color Formats** section above to visualize HSV colors.\n",
        "* Copy the image into an image editing software (gimp, paint, etc.) and use the eyedropper (color picker) tool to show the HSV values of the pixels in the stop sign.\n",
        "* Saturation and value vary a lot with lighting, but hue will remain mostly constant for a given object. Try using a wide range for value and saturation but a tight range for hue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FJWjKZ3Q3Du"
      },
      "outputs": [],
      "source": [
        "# TODO: change these bounds\n",
        "hsv_lower = (0, 0, 0)\n",
        "hsv_upper = (180, 255, 255)\n",
        "\n",
        "mask = get_mask(sign_img, hsv_lower, hsv_upper)\n",
        "\n",
        "plt.imshow(mask);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giajvA7UQ3Dw"
      },
      "source": [
        "We can use this mask as a filter for our original image to only keep portions that were between `hsv_lower` and `hsv_upper`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMA_1kCwQ3Dw"
      },
      "outputs": [],
      "source": [
        "masked_image = cv2.bitwise_and(sign_img, sign_img, mask=mask)\n",
        "plt.imshow(masked_image);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2iF0OHmQ3Dx"
      },
      "source": [
        "<a id=\"FindingContours\"></a>\n",
        "## 5. Finding Contours\n",
        "\n",
        "Now that we have a mask, we can create outlines called _contours_ around each object in the mask.  We will use these outlines to identify the largest object and calculates its size and position.\n",
        "\n",
        "First, we will use the OpenCV function `findContours`(docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#gadf1ad6a0b82947fa1fe3c3d497f260e0) to create a list of contours around each distinct object in the mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LPVbxjpQ3Dx"
      },
      "outputs": [],
      "source": [
        "def find_contours(mask):\n",
        "    \"\"\"\n",
        "    Returns a list of contours around all objects in a mask.\n",
        "    \"\"\"\n",
        "    return cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQxcDcbQQ3Dy"
      },
      "source": [
        "`find_contours` will return a list containing multiple contours if there are multiple distinct objects which fall between `hsv_lower` and `hsv_upper`.  This might occur if there are multiple stop signs in the image or if there are other objects that have a similar color to the stop sign(s)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 6\n",
        "\n",
        "Let's write a helper function to identify the largest contour, which we will assume is the closest stop sign.  This helper function should also ignore contours below a minimum size (such as `20 pixels`), since anything below this size is likely too small to be recognized.\n",
        "\n",
        "**Finish writing `get_largest_contour` so that it returns the largest contour larger than `min_area`, or returns `None` if no such contour exists.**  \n",
        "\n",
        "You will likely wish to use the OpenCV `contourArea` (docs.opencv.org/4.2.0/d3/dc0/group__imgproc__shape.html#ga2c759ed9f497d4a618048a2f56dc97f1) function to find the number of pixels in a contour."
      ],
      "metadata": {
        "id": "sfbfrSXO7gI1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K08Jm87VQ3Dz"
      },
      "outputs": [],
      "source": [
        "def get_largest_contour(contours, min_area=30):\n",
        "    \"\"\"\n",
        "    Finds the largest contour with size greater than min_area.\n",
        "\n",
        "    Args:\n",
        "        contours: A list of contours found in an image.\n",
        "        min_area: The smallest contour to consider (in number of pixels)\n",
        "\n",
        "    Returns:\n",
        "        The largest contour from the list, or None if no contour was larger than min_area.\n",
        "    \"\"\"\n",
        " #   if len(contours) == 0:\n",
        "        # TODO: What should we return if the list of contours is empty?\n",
        "\n",
        "    \n",
        "    # TODO: Return the largest contour, but return None if no contour is larger than min_area\n",
        "\n",
        "\n",
        "    return greatest_contour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1WxDiW_Q3D0"
      },
      "source": [
        "Let's try it out.  The following code block uses `find_contours` and `get_largest_contour` to find the largest contour and draw it on the image.  We should now see a green outline surrounding the closest stop sign in our image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS-4b5xGQ3D0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Find the largest contour\n",
        "contours = find_contours(mask)\n",
        "largest_contour = get_largest_contour(contours)\n",
        "\n",
        "# Draw it on the image\n",
        "image_copy = np.copy(sign_img)\n",
        "draw_contour(image_copy, largest_contour)\n",
        "plt.imshow(image_copy);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sayytda1Q3D1"
      },
      "source": [
        "<a id=\"ContourCenter\"></a>\n",
        "## 6. Contour Center\n",
        "\n",
        "One advantage of contours is that we can use them to easily calculate the center of an object.  Specifically, we will use the contour's _Moments_ (en.wikipedia.org/wiki/Image_moment), which are weighted averages of the pixels in the contour.  We can calculate the moment $M_{ij}$ with the following formula:\n",
        "\n",
        "```\n",
        "def moment(i, j):\n",
        "    sum = 0\n",
        "    for pixel in contour:\n",
        "        sum += pixel.x_position ** i + pixel.y_position ** j\n",
        "    return sum\n",
        "```\n",
        "\n",
        "To calculate contour center, we will use the following moments:\n",
        "\n",
        "* $M_{00}$: The number of pixels in the contour.\n",
        "* $M_{10}$: The sum of how far to the right each pixel in the contour is.\n",
        "* $M_{01}$: The sum of how far down each pixel in the contour is.\n",
        "\n",
        "Using the center of mass equation (en.wikipedia.org/wiki/Center_of_mass), $\\frac{M_{10}}{M_{00}}$ gives us the average horizontal position (column) of the contour, and $\\frac{M_{01}}{M_{00}}$ gives us the average vertical position (row).\n",
        "\n",
        "We can access these moments from OpenCV's moments calculation using M['m00'], M['m01'], and M['m10']."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 7\n",
        "\n",
        "Complete the `get_contour_center` function below to find the contour center. \n",
        "\n",
        "**Please calculate the center row and column of the contour using the Moments.**"
      ],
      "metadata": {
        "id": "_87McKe57Xh8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyuaWHZ-Q3D1"
      },
      "outputs": [],
      "source": [
        "def get_contour_center(contour):\n",
        "    \"\"\"\n",
        "    Finds the center of a contour from an image.\n",
        "\n",
        "    Args:\n",
        "        contour: The contour of which to find the center.\n",
        "\n",
        "    Returns:\n",
        "        The (row, column) of the pixel at the center of the contour, or None if the contour is empty.\n",
        "    \"\"\"\n",
        "    # Ask OpenCV to calculate the contour's moments\n",
        "    M = cv2.moments(contour)\n",
        "\n",
        "    # Check that the contour is not empty\n",
        "    if M[\"m00\"] <= 0:\n",
        "        return None\n",
        "\n",
        "    # TODO: Compute the center of mass of the contour\n",
        "    center_row = 0\n",
        "    center_column = 0\n",
        "    \n",
        "    return (center_row, center_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVs1Hbr4Q3D2"
      },
      "source": [
        "To see if this worked, we will draw a dot at this calculated center point. We should now see a yellow dot at the center of the stop sign."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFlL6-baQ3D2",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "center = get_contour_center(largest_contour)\n",
        "\n",
        "# Draw a circle at the contour center\n",
        "draw_circle(image_copy, center)\n",
        "plt.imhshow(image_copy);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0-Rjf7LQ3D3"
      },
      "source": [
        "<a id=\"ContourArea\"></a>\n",
        "## 7. Contour Area\n",
        "\n",
        "Contour area is also helpful for calculating how far an object is from the camera, since the closer an object is, the more pixels it will take up on the screen."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 8\n",
        "\n",
        "In this section, we will measure the area of a **different** stop sign. \n",
        "\n",
        "Using previous examples from this notebook, **update the following code block to load a different stop sign image, find the largest contour, print the contour area, and display the image with the contour.**"
      ],
      "metadata": {
        "id": "Hu-glDra9bLo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDf4seNMQ3D4"
      },
      "outputs": [],
      "source": [
        "# TODO: Load a different stop sign image from the 21 stop sign images\n",
        "\n",
        "\n",
        "# TODO: Find the largest contour\n",
        "\n",
        "\n",
        "# TODO: Calculate and print the largest contour's area\n",
        "\n",
        "\n",
        "# TODO: Display a copy of the image with the contour drawn on top\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BWSI UAV 2022 - Segmentation Practical.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}